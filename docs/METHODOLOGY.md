# Методология экспериментального исследования производительности криптографических алгоритмов с применением методов математической статистики и теории оптимизации

---

## ТЕОРЕТИКО-МЕТОДОЛОГИЧЕСКИЕ ОСНОВАНИЯ

### Литературные источники методологии

1. **Боровков А.А.** "Математическая статистика" (М.: Наука, 1984) — классический учебник теории статистических оценок и проверки гипотез

2. **Налимов В.В., Чернова Н.А.** "Статистические методы планирования экстремальных экспериментов" (М.: Наука, 1965) — методы оптимального планирования и обработки результатов вычислительных экспериментов

3. **Ермаков С.М., Жиглявский А.А.** "Математическая теория оптимального эксперимента" (Л.: Наука, 1987) — теория построения оптимальных планов эксперимента

4. **Вентцель Е.С.** "Теория вероятностей" (М.: Наука, 1969) — фундаментальные основы теории вероятностей и случайных величин

5. **Гмурман В.Е.** "Теория вероятностей и математическая статистика" (М.: Высшая школа, 2003) — практические методы статистической обработки экспериментальных данных

6. **Кобзарь А.И.** "Прикладная математическая статистика. Для инженеров и научных работников" (М.: Физматлит, 2006) — методы обработки экспериментальных данных

7. **Зайдель А.Н.** "Погрешности измерений физических величин" (Л.: Наука, 1985) — теория погрешностей и их распространения

8. **Рабинович С.Г.** "Погрешности измерений" (Л.: Энергия, 1978) — классический труд по теории измерений и оценке погрешностей

9. **Моисеев Н.Н., Иванилов Ю.П., Столярова Е.М.** "Методы оптимизации" (М.: Наука, 1978) — математические методы оптимизации

10. **Amda

hl G.M.** "Validity of the single processor approach to achieving large scale computing capabilities" (AFIPS Conference Proceedings, 1967) — закон Амдаля для параллельных вычислений

---

## 1. ПРЕДМЕТ И ОБЪЕКТ ИССЛЕДОВАНИЯ

### 1.1. Объект исследования

**Объектом исследования** является программная реализация постквантового криптографического алгоритма SABER (модульная схема инкапсуляции ключей на основе задачи Learning With Rounding на решетках).

**Конкретизация объекта**:
- Базовая реализация (DEFAULT) — эталонная реализация без оптимизаций
- Оптимизированная реализация FAST_V4 — с использованием NEON SIMD и асимметричного умножения
- Реализация с ГОСТ стандартами (GOST_FAST) — с применением ГОСТ Стрибог-512 и Incomplete-NTT

### 1.2. Предмет исследования

**Предметом исследования** является временная эффективность выполнения криптографических операций (генерация ключей, инкапсуляция, декапсуляция) в различных конфигурациях реализации и при различных режимах обработки (последовательный, батчинговый).

### 1.3. Цель исследования

**Целью** является количественная оценка эффективности применения оптимизационных техник (SIMD векторизация, батчинг, специализированные алгоритмы умножения полиномов) для криптографических операций на процессорах архитектуры ARM64.

### 1.4. Задачи исследования

1. Разработать методику экспериментального измерения временных характеристик криптографических операций
2. Определить метрики и показатели эффективности оптимизаций
3. Обосновать методы статистической обработки экспериментальных данных
4. Установить критерии валидности и воспроизводимости экспериментов
5. Разработать протокол проведения эксперимента
6. Провести анализ полученных результатов с применением методов математической статистики

---

## 2. ПОНЯТИЙНЫЙ АППАРАТ И ОПРЕДЕЛЕНИЯ

### 2.0. Методологические принципы выбора статистических методов

**Принцип несмещенности**. Для оценок параметров $\hat{\theta}$ требуется выполнение условия $\mathbb{E}[\hat{\theta}] = \theta$, где $\theta$ — истинное значение параметра. Несмещенность обеспечивает отсутствие систематической ошибки: при многократном повторении эксперимента среднее значение оценки сходится к истинному значению параметра. Для измерения времени выполнения это критически важно, так как систематические ошибки в оценке среднего времени или дисперсии приводят к некорректным доверительным интервалам и ошибочным выводам об эффективности оптимизаций.

**Принцип оптимальности**. Среди несмещенных оценок выбираются оптимальные по критерию минимума дисперсии (эффективные оценки). Согласно теореме Гаусса-Маркова, для линейных моделей наилучшая линейная несмещенная оценка (BLUE — Best Linear Unbiased Estimator) обладает минимальной дисперсией среди всех линейных несмещенных оценок. Для нормального распределения выборочное среднее $\bar{T}$ достигает нижней границы Рао-Крамера и является эффективной оценкой. Минимальная дисперсия оценки обеспечивает максимальную точность при заданном объеме выборки, что позволяет достигать требуемой относительной погрешности $\delta < 1\%$ при разумном $N$.

**Принцип максимальной мощности**. Для статистических критериев выбираются тесты, обладающие максимальной мощностью при заданном уровне значимости $\alpha$. Согласно лемме Неймана-Пирсона, при проверке простой гипотезы против простой альтернативы существует наиболее мощный критерий (uniformly most powerful test). Для нормального распределения t-критерий Стьюдента является UMP-тестом. Максимальная мощность означает максимальную вероятность обнаружения различий при их наличии, что критично для выявления эффекта оптимизаций при ограниченном объеме выборки.

**Принцип соответствия предположений природе данных**. Выбор параметрических или непараметрических методов обосновывается свойствами измеряемой величины. Для времени выполнения криптографических операций:
- Время $T = \sum_{i=1}^{K} t_i$, где $t_i$ — время элементарных операций (инструкций процессора).
- По центральной предельной теореме при $K \gg 1$ распределение $T$ стремится к нормальному независимо от распределения $t_i$.
- Эмпирическая проверка: при контролируемых условиях (фиксированная частота, изоляция процесса) коэффициент вариации $CV < 10\%$ свидетельствует о нормальности.
- Следовательно, применение параметрических методов (t-тест, доверительные интервалы на основе распределения Стьюдента) математически обосновано.

**Принцип объективности**. Статистические методы не должны зависеть от субъективных предположений исследователя. Частотный подход к построению доверительных интервалов дает интервал $[L, U]$, для которого $P_{\theta}(L \leq \theta \leq U) = 1 - \alpha$ при любом истинном $\theta$, без необходимости задания априорного распределения $p(\theta)$. Байесовский подход требует выбора априорного распределения, что вносит субъективность: разные исследователи могут получить различные апостериорные интервалы на основе одних и тех же данных. Для измерения производительности, где априорная информация о распределении времени выполнения отсутствует, частотный подход обеспечивает объективность результатов.

**Принцип робастности при больших выборках**. При объеме выборки $N \geq 100$ параметрические методы, основанные на предположении нормальности, сохраняют корректность даже при умеренных отклонениях от нормальности. Согласно центральной предельной теореме, распределение выборочного среднего $\bar{T} \sim \mathcal{N}(\mu, \sigma^2/N)$ при $N \to \infty$ независимо от распределения исходных $T_i$. Для $N = 1000$ (принятого в протоколе) нормальность $\bar{T}$ обеспечена с высокой точностью, что гарантирует корректность доверительных интервалов и статистических тестов даже при незначительных нарушениях нормальности исходного распределения.

---

### 2.1. Основные понятия теории измерений

**Определение 2.1.1** (Измеримая величина). **Измеримой величиной** называется физическая величина, значение которой может быть определено посредством измерения. В контексте исследования — это время выполнения криптографической операции.

**Определение 2.1.2** (Истинное значение). **Истинным значением** физической величины называется значение, идеальным образом отражающее свойство данного объекта. Обозначение: $\mu$ (математическое ожидание времени выполнения).

**Определение 2.1.3** (Результат измерения). **Результатом измерения** называется значение величины, найденное путем измерения. Обозначение: $T_i$ — результат $i$-го измерения времени.

**Определение 2.1.4** (Погрешность измерения). **Погрешностью измерения** называется отклонение результата измерения от истинного значения измеряемой величины:
$$
\Delta T_i = T_i - \mu.
$$

### 2.2. Классификация погрешностей (по Рабиновичу С.Г.)

**Систематическая погрешность** $\theta$ — составляющая погрешности, остающаяся постоянной или закономерно изменяющаяся при повторных измерениях.

**Примеры**:
- Смещение таймера процессора
- Накладные расходы вызова функции измерения времени
- Влияние фоновых процессов операционной системы

**Случайная погрешность** $\varepsilon$ — составляющая погрешности, изменяющаяся случайным образом при повторных измерениях.

**Примеры**:
- Вариации времени доступа к кэшу
- Прерывания от аппаратных устройств
- Флуктуации частоты процессора

**Математическая модель** (по Зайделю А.Н.):
$$
T_i = \mu + \theta + \varepsilon_i,
$$
где $\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$ — случайная величина с нормальным распределением.

### 2.3. Определения временных характеристик

**Определение 2.3.1** (Время выполнения операции). Пусть $f: \mathcal{D} \to \mathcal{R}$ — детерминированная функция (криптографическая операция), отображающая область определения $\mathcal{D}$ (входные данные) в область значений $\mathcal{R}$ (результат). **Временем выполнения** операции $f$ на входе $x \in \mathcal{D}$ называется величина
$$
T(f, x) = t_{\text{завершения}} - t_{\text{начала}},
$$
измеренная монотонными часами процессора.

**Единица измерения**: микросекунды (мкс, μs), $1~\text{мкс} = 10^{-6}$ с.

**Определение 2.3.2** (Среднее время выполнения). Для фиксированной операции $f$ **средним временем выполнения** называется математическое ожидание случайной величины $T(f, X)$, где $X$ — случайный вход из распределения $P_{\mathcal{D}}$:
$$
\mu_f = \mathbb{E}[T(f, X)] = \int_{\mathcal{D}} T(f, x) dP_{\mathcal{D}}(x).
$$

**На практике**: Используется выборочное среднее по фиксированному набору входов.

**Определение 2.3.3** (Пропускная способность). **Пропускной способностью** (throughput) операции $f$ называется величина
$$
\Theta(f) = \frac{1}{\mu_f},
$$
измеряемая в операциях в секунду (ops/s, оп/с).

**Физический смысл**: Количество операций, которое может быть выполнено за единицу времени при последовательном выполнении.

**Определение 2.3.4** (Латентность). **Латентностью** (latency) называется время от начала выполнения операции до получения результата. В контексте одиночных операций совпадает с временем выполнения: $L(f) = \mu_f$.

---

## 3. МЕТРИКИ ЭФФЕКТИВНОСТИ ОПТИМИЗАЦИЙ

### 3.1. Коэффициент ускорения

**Определение 3.1.1** (Коэффициент ускорения, speedup). Пусть $T_{\text{базовая}}$ — среднее время выполнения базовой реализации алгоритма, $T_{\text{опт}}$ — среднее время оптимизированной реализации. **Коэффициентом ускорения** называется безразмерная величина
$$
S = \frac{T_{\text{базовая}}}{T_{\text{опт}}}.
$$

**Интерпретация**:
- $S > 1$ — оптимизация дает ускорение (положительный эффект)
- $S = 1$ — оптимизация не дает эффекта
- $S < 1$ — оптимизация приводит к замедлению (отрицательный эффект)

**Терминология**:
- $S = 2$ — "двукратное ускорение", "в 2 раза быстрее"
- $S = 1.5$ — "ускорение в 1.5 раза", "на 50% быстрее"

**Связь с относительным улучшением**:
$$
\text{Улучшение (\%)} = (S - 1) \times 100\%.
$$

**Пример**:
$$
S = 1.34 \Rightarrow \text{Улучшение} = 0.34 \times 100\% = 34\%.
$$

### 3.2. Эффективность и масштабируемость

**Определение 3.2.1** (Эффективность параллелизации). Для алгоритма, использующего $p$ параллельных ресурсов (процессоров, SIMD-каналов), **эффективностью параллелизации** называется величина
$$
E = \frac{S}{p},
$$
где $S$ — достигнутое ускорение.

**Интерпретация**:
- $E = 1$ — идеальная эффективность (линейное масштабирование)
- $0.5 \leq E < 1$ — хорошая эффективность
- $E < 0.5$ — низкая эффективность

**Определение 3.2.2** (Эффективность батчинга). Пусть операция обрабатывает $n$ независимых входов. Обозначим:
- $T_{\text{посл}}(n)$ — время последовательной обработки $n$ операций
- $T_{\text{батч}}(n)$ — время батчинговой обработки $n$ операций

**Эффективностью батчинга** называется
$$
E_{\text{батч}}(n) = \frac{T_{\text{посл}}(n)}{T_{\text{батч}}(n)} = \frac{n \cdot T_{\text{одна}}}{T_{\text{батч}}(n)},
$$
где $T_{\text{одна}}$ — время одной операции.

**Частный случай** ($n = 2$, двойной батчинг):
$$
E_{\text{батч}}(2) = \frac{2 T_{\text{одна}}}{T_{\text{батч}}(2)}.
$$

**Физический смысл**: Во сколько раз батчинг эффективнее последовательного выполнения.

**Пример**:
$$
T_{\text{одна}} = 33.87~\text{мкс}, \quad T_{\text{батч}}(2) = 50.50~\text{мкс}.
$$
$$
E_{\text{батч}}(2) = \frac{2 \times 33.87}{50.50} = \frac{67.74}{50.50} = 1.34.
$$

**Интерпретация**: Батчинг в 1.34 раза эффективнее последовательного выполнения двух операций.

### 3.3. Закон Амдаля (Amdahl's Law)

**Теорема 3.3.1** (Амдаль, 1967). Пусть доля кода, поддающаяся параллелизации, равна $p \in [0, 1]$, а $(1-p)$ — последовательная часть. При использовании $n$ параллельных ресурсов максимально достижимое ускорение ограничено величиной
$$
S_{\max}(n) = \frac{1}{(1-p) + \frac{p}{n}}.
$$

**Следствие** (предельный случай):
$$
\lim_{n \to \infty} S_{\max}(n) = \frac{1}{1-p}.
$$

**Применение к батчингу SABER**. Рассмотрим декомпозицию операции KeyGen:
- $T_{\text{матрица}}$ — генерация матрицы $\mathbf{A}$ (выполняется 1 раз при батчинге)
- $T_{\text{секрет}}$ — генерация секрета (выполняется $n$ раз)
- $T_{\text{умножение}}$ — умножение матрицы на вектор (выполняется $n$ раз)

**Доля разделяемого кода**:
$$
p = \frac{T_{\text{матрица}}}{T_{\text{матрица}} + T_{\text{секрет}} + T_{\text{умножение}}}.
$$

**Пример**. Если $T_{\text{матрица}} = 10.2$ мкс, $T_{\text{total}} = 33.9$ мкс:
$$
p = \frac{10.2}{33.9} = 0.30 \quad (30\%).
$$

**Максимальное ускорение** при $n \to \infty$:
$$
S_{\max} = \frac{1}{1 - 0.30} = \frac{1}{0.70} = 1.43.
$$

**Вывод**: Даже при идеальной параллелизации остального кода, ускорение не превысит $1.43 \times$ из-за последовательной части.

**Для $n=2$** (реальный батчинг):
$$
S_{\text{теория}}(2) = \frac{1}{0.70 + \frac{0.30}{2}} = \frac{1}{0.85} = 1.18.
$$

**Сравнение с экспериментом**: $S_{\text{эксп}} = 1.34 > 1.18$ означает дополнительный выигрыш от SIMD-оптимизаций и улучшенной локальности кэша.

---

## 4. СТАТИСТИЧЕСКИЕ МЕТОДЫ ОБРАБОТКИ ДАННЫХ

### 4.1. Выборочные характеристики

**Генеральная совокупность** — множество всех возможных измерений времени выполнения операции при различных состояниях системы.

**Выборка** — конечное множество $\{T_1, T_2, \ldots, T_N\}$ измерений, полученных в эксперименте.

**Объем выборки** — $N$ (количество измерений).

#### 4.1.1. Выборочное среднее

**Определение**:
$$
\bar{T} = \frac{1}{N} \sum_{i=1}^{N} T_i.
$$

**Свойства**:
- Является несмещенной оценкой математического ожидания: $\mathbb{E}[\bar{T}] = \mu$
- Дисперсия: $\text{Var}[\bar{T}] = \sigma^2 / N$
- При $N \to \infty$: $\bar{T} \xrightarrow{P} \mu$ (состоятельность)

#### 4.1.2. Выборочная дисперсия

**Определение** (несмещенная оценка):
$$
s^2 = \frac{1}{N-1} \sum_{i=1}^{N} (T_i - \bar{T})^2.
$$

**Обоснование делителя** $(N-1)$: Используется $N-1$ степеней свободы, так как одна степень "потрачена" на оценку $\bar{T}$.

#### Обоснование выбора несмещенной оценки дисперсии

**Альтернативные определения дисперсии**:

1. **Смещенная оценка** (оценка максимального правдоподобия):
   $$
   \tilde{s}^2 = \frac{1}{N} \sum_{i=1}^{N} (T_i - \bar{T})^2.
   $$
   **Математическое ожидание**: $\mathbb{E}[\tilde{s}^2] = \frac{N-1}{N} \sigma^2 < \sigma^2$ (систематическое занижение на величину $\sigma^2/N$).

2. **Несмещенная оценка** (с поправкой Бесселя):
   $$
   s^2 = \frac{1}{N-1} \sum_{i=1}^{N} (T_i - \bar{T})^2.
   $$
   **Математическое ожидание**: $\mathbb{E}[s^2] = \sigma^2$ (точное равенство).

**Математическое обоснование выбора несмещенной оценки**:

1. **Потеря степени свободы**. При вычислении $\sum_{i=1}^{N} (T_i - \bar{T})^2$ используется выборочное среднее $\bar{T}$ вместо истинного $\mu$. Это накладывает связь $\sum_{i=1}^{N} (T_i - \bar{T}) = 0$, что снижает число независимых отклонений с $N$ до $N-1$. Математически строгое доказательство:
   $$
   \mathbb{E}\left[\sum_{i=1}^{N} (T_i - \bar{T})^2\right] = \mathbb{E}\left[\sum_{i=1}^{N} (T_i - \mu)^2 - N(\bar{T} - \mu)^2\right] = N\sigma^2 - \sigma^2 = (N-1)\sigma^2.
   $$
   Следовательно, несмещенная оценка требует деления на $(N-1)$, а не на $N$.

2. **Корректность статистики Стьюдента**. Теорема: для выборки из $\mathcal{N}(\mu, \sigma^2)$ статистика
   $$
   t = \frac{\bar{T} - \mu}{s/\sqrt{N}}, \quad \text{где } s^2 = \frac{1}{N-1} \sum_{i=1}^{N} (T_i - \bar{T})^2,
   $$
   имеет распределение Стьюдента с $\nu = N - 1$ степенями свободы. Использование смещенной оценки $\tilde{s}^2$ приводит к статистике $\tilde{t} = (\bar{T} - \mu) / (\tilde{s}/\sqrt{N})$, которая НЕ имеет распределения Стьюдента. Это влечет некорректность доверительных интервалов: при использовании $\tilde{s}^2$ реальный уровень доверия будет ниже заявленного $1 - \alpha$.

3. **Количественная оценка систематической ошибки**. Смещение оценки МП:
   $$
   \text{bias}(\tilde{s}^2) = \mathbb{E}[\tilde{s}^2] - \sigma^2 = -\frac{\sigma^2}{N}.
   $$
   Для $N = 100$ относительное смещение составляет $1\%$, для $N = 10$ — $10\%$. При малых выборках систематическая ошибка соизмерима со случайной, что недопустимо при требовании $\delta < 1\%$.

4. **Следствие для доверительных интервалов**. Использование смещенной оценки приводит к систематическому занижению ширины доверительного интервала на величину
   $$
   \Delta_{\text{ДИ}} = t_{1-\alpha/2, N-1} \frac{(\sigma - \tilde{s})}{\sqrt{N}} \approx t_{1-\alpha/2, N-1} \frac{\sigma}{2N\sqrt{N}}.
   $$
   Для $N = 100$ это составляет $\approx 0.5\%$ ширины интервала, что сравнимо с требуемой точностью $\delta < 1\%$ и может привести к ложной уверенности в точности оценки.

**Вывод**: Несмещенная оценка $s^2$ с делителем $(N-1)$ является единственной корректной для построения доверительных интервалов и проверки гипотез на основе распределения Стьюдента. Систематическая ошибка смещенной оценки МП несовместима с требованием высокой точности измерения производительности ($\delta < 1\%$).

#### 4.1.3. Выборочное стандартное отклонение

**Определение**:
$$
s = \sqrt{s^2} = \sqrt{\frac{1}{N-1} \sum_{i=1}^{N} (T_i - \bar{T})^2}.
$$

**Физический смысл**: Характеризует разброс измерений вокруг среднего значения.

#### 4.1.4. Коэффициент вариации

**Определение**:
$$
CV = \frac{s}{\bar{T}} \times 100\%.
$$

**Интерпретация** (по Кобзарю А.И.):
- $CV < 5\%$ — отличная стабильность (слабая вариабельность)
- $5\% \leq CV < 10\%$ — хорошая стабильность (умеренная вариабельность)
- $10\% \leq CV < 20\%$ — удовлетворительная стабильность
- $CV \geq 20\%$ — высокая вариабельность, требуется улучшение условий эксперимента

**Критерий для валидных экспериментов**: $CV < 10\%$.

### 4.2. Доверительные интервалы

#### 4.2.1. Доверительный интервал для среднего (малые выборки)

**Теорема 4.2.1** (Стьюдента). Пусть $T_1, \ldots, T_N$ — независимая выборка из нормального распределения $\mathcal{N}(\mu, \sigma^2)$. Тогда статистика
$$
t = \frac{\bar{T} - \mu}{s / \sqrt{N}}
$$
имеет распределение Стьюдента с $\nu = N - 1$ степенями свободы.

**Доверительный интервал** с уровнем доверия $1 - \alpha$:
$$
\bar{T} - t_{1-\alpha/2, N-1} \frac{s}{\sqrt{N}} \leq \mu \leq \bar{T} + t_{1-\alpha/2, N-1} \frac{s}{\sqrt{N}},
$$
где $t_{1-\alpha/2, N-1}$ — квантиль распределения Стьюдента уровня $1 - \alpha/2$.

**Для $\alpha = 0.05$ (95% ДИ)**:
- $N = 10$: $t_{0.975, 9} = 2.262$
- $N = 30$: $t_{0.975, 29} = 2.045$
- $N = 100$: $t_{0.975, 99} = 1.984$
- $N = 1000$: $t_{0.975, 999} = 1.962$

#### 4.2.2. Доверительный интервал для среднего (большие выборки)

**Центральная предельная теорема** (ЦПТ). При $N \geq 30$ распределение $\bar{T}$ приближается к нормальному $\mathcal{N}(\mu, \sigma^2/N)$ независимо от распределения исходной выборки.

**Доверительный интервал** (аппроксимация):
$$
\mu \in \left[\bar{T} - z_{1-\alpha/2} \frac{s}{\sqrt{N}}, \bar{T} + z_{1-\alpha/2} \frac{s}{\sqrt{N}}\right],
$$
где $z_{1-\alpha/2}$ — квантиль стандартного нормального распределения.

**Для $\alpha = 0.05$**: $z_{0.975} = 1.96$.

**Пример**. $\bar{T} = 33.87$ мкс, $s = 1.52$ мкс, $N = 1000$:
$$
\mu \in \left[33.87 - 1.96 \times \frac{1.52}{\sqrt{1000}}, 33.87 + 1.96 \times \frac{1.52}{\sqrt{1000}}\right]
$$
$$
= [33.87 - 0.094, 33.87 + 0.094] = [33.78, 33.96]~\text{мкс}.
$$

#### Обоснование выбора классических (частотных) доверительных интервалов

**Альтернативные подходы к построению интервальных оценок**:

1. **Классический (частотный) доверительный интервал** (Нейман-Пирсон):
   - Определение: Интервал $[L, U]$, для которого $P(L \leq \mu \leq U) = 1 - \alpha$ при многократном повторении эксперимента.
   - Интерпретация: При проведении 100 экспериментов приблизительно в 95 из них истинное значение $\mu$ попадет в построенный интервал.
   - Объективность: Не требует задания априорного распределения.

2. **Байесовский доверительный интервал** (credible interval):
   - Определение: Интервал $[L, U]$, для которого $P(L \leq \mu \leq U \mid \text{данные}) = 1 - \alpha$ при заданном априорном распределении $p(\mu)$.
   - Интерпретация: Вероятность того, что истинное значение находится в интервале, равна $1 - \alpha$ (субъективная вероятность).
   - Субъективность: Требует выбора априорного распределения $p(\mu)$.

3. **Фидуциальные интервалы** (Фишер):
   - Историческая концепция, не получившая широкого распространения.
   - Проблемы с математической строгостью в общем случае.

**Математическое и методологическое обоснование выбора классического подхода**:

1. **Объективность и независимость от априорных предположений**. Частотный доверительный интервал $[L, U]$ обладает свойством:
   $$
   P_{\theta}(L(X_1, \ldots, X_N) \leq \theta \leq U(X_1, \ldots, X_N)) = 1 - \alpha \quad \forall \theta \in \Theta,
   $$
   где вероятность вычисляется по распределению выборки при фиксированном (но неизвестном) $\theta$. Это свойство выполняется независимо от какого-либо априорного распределения $p(\theta)$ и не требует предположений о вероятностной природе параметра.

   Байесовский интервал дает:
   $$
   P(\theta \in [L, U] \mid X_1, \ldots, X_N) = 1 - \alpha,
   $$
   что требует задания $p(\theta)$ и интерпретации $\theta$ как случайной величины. Для времени выполнения криптографической операции параметр $\mu$ (среднее время) является детерминированной (хотя и неизвестной) характеристикой системы, а не случайной величиной, что делает байесовскую интерпретацию неестественной.

2. **Отсутствие априорной информации**. Для построения байесовского интервала необходимо специфицировать априорное распределение $p(\mu)$. Для времени выполнения новой оптимизации такая информация отсутствует. Использование "неинформативных" априорных распределений (равномерное, Джеффриса) вносит искусственные предположения:
   - Равномерное на $[0, \infty)$ — improper prior, требует регуляризации.
   - Априорное Джеффриса $p(\mu, \sigma^2) \propto 1/\sigma^2$ — приводит к интервалам, близким к частотным, но с дополнительной вычислительной сложностью.

   Частотный подход не требует таких предположений и дает корректные интервалы без апелляции к априорным вероятностям.

3. **Гарантированное покрытие при повторных экспериментах**. Свойство частотного ДИ $P(L \leq \mu \leq U) = 0.95$ означает: если провести 1000 независимых экспериментов и для каждого построить 95% ДИ, то приблизительно в $950 \pm \sqrt{1000 \times 0.95 \times 0.05} \approx 950 \pm 7$ интервалах истинное $\mu$ будет накрыто. Это свойство проверяемо и не зависит от субъективных убеждений.

   Байесовский интервал такого свойства не имеет: его покрытие зависит от соответствия априорного распределения реальности, что непроверяемо.

4. **Воспроизводимость и объективная верификация результатов**. Два исследователя, применяя частотный метод к одним данным, получат идентичные интервалы. Различия в байесовских интервалах возникают при различных априорных распределениях:
   - Исследователь A: $p(\mu) = \text{Uniform}(0, 1000)$ мкс
   - Исследователь B: $p(\mu) = \text{Jeffreys}$

   Это препятствует независимой репликации результатов, что критично для научной методологии.

5. **Соответствие целям исследования**. Цель — количественная оценка эффективности оптимизаций с гарантией точности $\delta < 1\%$ при уровне доверия 95%. Частотная интерпретация напрямую дает операциональное значение: если повторить эксперимент, в 95% случаев истинное значение попадет в интервал. Это соответствует требованиям воспроизводимости научных результатов. Байесовская интерпретация ("вероятность того, что $\mu$ в интервале") не дает гарантий при повторных экспериментах.

**Когда байесовский подход обоснован** (для полноты методологической картины):
- Наличие обоснованной априорной информации из массива предыдущих экспериментов (например, мета-анализ производительности на семействе процессоров).
- Последовательный дизайн эксперимента с обновлением оценок по мере поступления данных.
- Принятие решений в условиях неопределенности, где требуется количественная оценка вероятностей различных значений параметра.

**Вывод**: Частотные доверительные интервалы выбраны на основании объективности (независимости от априорных предположений), гарантированного покрытия при повторных экспериментах, воспроизводимости результатов и соответствия операциональной цели исследования — верификации эффективности оптимизаций с количественной гарантией точности.

### 4.3. Относительная погрешность

**Определение**:
$$
\delta_{\bar{T}} = \frac{\Delta \bar{T}}{\bar{T}} \times 100\%,
$$
где $\Delta \bar{T} = t_{1-\alpha/2, N-1} \times s / \sqrt{N}$ — полуширина доверительного интервала.

**Требование для высокоточных измерений**: $\delta_{\bar{T}} < 1\%$.

**Связь с объемом выборки**:
$$
\delta_{\bar{T}} \sim \frac{1}{\sqrt{N}}.
$$

**Для обеспечения** $\delta < 1\%$ при $CV = 5\%$:
$$
N \geq \left(\frac{1.96 \times CV}{\delta}\right)^2 = \left(\frac{1.96 \times 5}{1}\right)^2 = 96 \approx 100.
$$

**Практическая рекомендация**: $N \geq 1000$ для гарантии $\delta < 1\%$ при $CV \leq 10\%$.

### 4.4. Обработка выбросов

**Определение 4.4.1** (Выброс, outlier). Измерение $T_i$ называется **выбросом**, если оно существенно отклоняется от основной массы данных.

**Критерий 3σ** (правило трех сигм, метод Налимова):
$$
|T_i - \bar{T}| > 3s \Rightarrow T_i~\text{является выбросом}.
$$

**Обоснование**: В нормальном распределении $\mathcal{N}(\mu, \sigma^2)$:
$$
P(|T - \mu| > 3\sigma) \approx 0.003 = 0.3\%.
$$

**Алгоритм обработки**:
1. Вычислить $\bar{T}$ и $s$ по полной выборке
2. Удалить элементы, удовлетворяющие $|T_i - \bar{T}| > 3s$
3. Пересчитать $\bar{T}$ и $s$ по очищенной выборке
4. Если удалено > 5% измерений, рекомендуется повторить эксперимент

**Альтернативные методы**:
- **Критерий Граббса** (для малых выборок)
- **Метод межквартильного размаха** (IQR): выброс если $T_i < Q_1 - 1.5 \times IQR$ или $T_i > Q_3 + 1.5 \times IQR$

#### Обоснование выбора критерия 3σ для обнаружения выбросов

**Альтернативные методы обнаружения выбросов**:

1. **Критерий 3σ** (правило трех сигм, метод Налимова):
   - Параметрический метод, основан на свойствах нормального распределения.
   - Выброс: $|T_i - \bar{T}| > 3s$.
   - Вероятность ложного обнаружения: $\approx 0.3\%$ для нормального распределения.

2. **Критерий Граббса**:
   - Параметрический метод для малых выборок ($N < 30$).
   - Проверка максимального отклонения: $G = \max_i |T_i - \bar{T}| / s$.
   - Сравнение с критическим значением из таблиц Граббса.
   - Более строгий, чем 3σ, для малых выборок.

3. **Метод межквартильного размаха** (IQR):
   - Непараметрический метод, робастный к виду распределения.
   - $IQR = Q_3 - Q_1$ (разность третьего и первого квартилей).
   - Выброс: $T_i < Q_1 - 1.5 \times IQR$ или $T_i > Q_3 + 1.5 \times IQR$.
   - Не требует нормальности, но менее мощный при нормальном распределении.

4. **Критерий Шовене**:
   - Параметрический метод, основан на вероятности события.
   - Выброс, если вероятность получить такое отклонение < $1/(2N)$.
   - Зависит от объема выборки.

**Математическое обоснование выбора критерия 3σ**:

1. **Вероятностное обоснование порога**. Для нормального распределения $\mathcal{N}(\mu, \sigma^2)$:
   $$
   P(|X - \mu| > 3\sigma) = 2\Phi(-3) = 2 \times 0.00135 = 0.0027,
   $$
   где $\Phi$ — функция распределения стандартной нормальной величины. Это означает, что валидное измерение из нормального распределения попадает за границу $3\sigma$ с вероятностью $\approx 0.27\%$. При объеме выборки $N = 1000$ ожидаемое число ложных обнаружений:
   $$
   \mathbb{E}[\text{ложных}] = N \times 0.0027 = 2.7 \approx 3.
   $$
   Это соответствует критерию "< 5% удаленных измерений" для валидности эксперимента.

2. **Оптимальность при нормальности**. Критерий 3σ эквивалентен тесту на выбросы с уровнем значимости $\alpha = 0.0027$. Для нормального распределения это обеспечивает оптимальный баланс:
   - Вероятность ошибки I рода (удаление валидного измерения): $0.27\%$ — низкая.
   - Вероятность ошибки II рода (пропуск выброса с отклонением > 5σ): < $10^{-6}$ — пренебрежимо мала.

   Для сравнения, метод IQR с порогом $1.5 \times IQR$ соответствует $\approx 2.7\sigma$ для нормального распределения, что дает вероятность ложного обнаружения $\approx 0.7\%$ — в 2.6 раза выше.

3. **Обоснованность предположения нормальности**. Время выполнения $T$ представляет собой сумму времен элементарных операций:
   $$
   T = \sum_{i=1}^{K} t_i + \varepsilon_{\text{система}},
   $$
   где $K \sim 10^6$  (число инструкций процессора), $\varepsilon_{\text{система}}$ — случайные задержки (cache miss, прерывания). По центральной предельной теореме при $K \gg 1$:
   $$
   T \xrightarrow{d} \mathcal{N}\left(\sum_{i=1}^{K} \mathbb{E}[t_i], \sum_{i=1}^{K} \text{Var}[t_i]\right).
   $$
   При контролируемых условиях (изоляция процесса, фиксированная частота) эмпирическая проверка дает $CV < 10\%$, что свидетельствует о близости к нормальному распределению. Следовательно, применение параметрического критерия 3σ математически обосновано.

4. **Мощность обнаружения аномальных измерений**. Выбросы в измерениях времени обусловлены:
   - Прерываниями от операционной системы → отклонение > 10σ
   - Вытеснением кэша → отклонение > 5σ
   - Переключением контекста → отклонение > 7σ

   Порог 3σ надежно обнаруживает такие аномалии (вероятность обнаружения > 99.9%), не удаляя валидные измерения с естественными флуктуациями (< 3σ).

5. **Сравнение с критерием Граббса**. Критерий Граббса основан на статистике:
   $$
   G = \frac{\max_i |T_i - \bar{T}|}{s}.
   $$
   Для $N = 1000$ критическое значение Граббса при $\alpha = 0.05$: $G_{\text{crit}} \approx 4.86$. Критерий 3σ эквивалентен порогу $G = 3$, что является более консервативным (удаляет меньше точек). Для больших выборок ($N > 100$) критерий Граббса асимптотически эквивалентен фиксированному порогу в единицах $\sigma$, поэтому преимущество критерия Граббса нивелируется.

6. **Робастность оценок среднего и дисперсии**. После удаления выбросов по критерию 3σ повторно вычисляемые $\bar{T}$ и $s$ являются более робастными оценками, чем исходные, при наличии контаминации (примесь измерений из распределения с тяжелыми хвостами). Математически: если $\varepsilon$ доля измерений из распределения с $\sigma_{\text{выброс}} \gg \sigma$, то смещение оценки $\bar{T}$ без фильтрации составляет $O(\varepsilon \sigma_{\text{выброс}})$, тогда как после фильтрации — $O(\varepsilon^2 \sigma)$.

**Недостатки и ограничения критерия 3σ**:
- При сильных нарушениях нормальности (асимметрия, тяжелые хвосты) вероятность ложных обнаружений может превышать 0.27%.
- Маскировочный эффект: множественные выбросы могут завышать $s$, делая выбросы незаметными (требуется итерационное применение).

**Условия применимости альтернативных методов**:
- **Критерий Граббса**: Для малых выборок ($N < 30$), где 3σ-правило недостаточно строгое.
- **Метод IQR**: При явных нарушениях нормальности (проверяется критерием Шапиро-Уилка, $p < 0.05$).

**Вывод**: Критерий 3σ выбран на основании вероятностного обоснования (оптимальный баланс ошибок I и II рода при нормальности), обоснованности предположения нормальности (ЦПТ для суммы элементарных операций), высокой мощности обнаружения реальных аномалий (прерывания, вытеснение кэша) и робастности оценок при наличии контаминации. Для $N = 1000$ и контролируемых условий эксперимента метод обеспечивает ожидаемое число ложных обнаружений < 3, что соответствует критерию валидности "< 5% удаленных измерений".

### 4.5. Проверка статистических гипотез

#### 4.5.1. Критерий Стьюдента для двух независимых выборок

**Задача**: Проверить, существует ли статистически значимое различие между двумя реализациями.

**Нулевая гипотеза**: $H_0: \mu_1 = \mu_2$ (средние равны, нет различия).

**Альтернативная гипотеза**:
- $H_1: \mu_1 \neq \mu_2$ (двусторонняя)
- $H_1: \mu_1 > \mu_2$ (односторонняя, для проверки ускорения)

**Статистика Стьюдента** (при равных дисперсиях):
$$
t = \frac{\bar{T}_1 - \bar{T}_2}{s_p \sqrt{\frac{1}{N_1} + \frac{1}{N_2}}},
$$
где
$$
s_p^2 = \frac{(N_1 - 1)s_1^2 + (N_2 - 1)s_2^2}{N_1 + N_2 - 2}
$$
— объединенная оценка дисперсии.

**Число степеней свободы**: $\nu = N_1 + N_2 - 2$.

**Решающее правило** (для уровня значимости $\alpha = 0.05$):
- Двусторонняя: Отвергаем $H_0$, если $|t| > t_{1-\alpha/2, \nu}$
- Односторонняя: Отвергаем $H_0$, если $t > t_{1-\alpha, \nu}$

**Критерий Уэлча** (при неравных дисперсиях):
$$
t = \frac{\bar{T}_1 - \bar{T}_2}{\sqrt{\frac{s_1^2}{N_1} + \frac{s_2^2}{N_2}}}.
$$

**Число степеней свободы** (формула Саттертуэйта):
$$
\nu = \frac{\left(\frac{s_1^2}{N_1} + \frac{s_2^2}{N_2}\right)^2}{\frac{(s_1^2/N_1)^2}{N_1-1} + \frac{(s_2^2/N_2)^2}{N_2-1}}.
$$

#### 4.5.2. p-значение

**Определение**. **p-значением** (p-value) называется вероятность получить наблюдаемое (или более экстремальное) значение статистики при условии истинности нулевой гипотезы.

**Интерпретация**:
- $p < 0.01$ — очень сильное свидетельство против $H_0$
- $0.01 \leq p < 0.05$ — сильное свидетельство против $H_0$ (стандартный уровень значимости)
- $0.05 \leq p < 0.10$ — слабое свидетельство против $H_0$
- $p \geq 0.10$ — недостаточно свидетельств для отклонения $H_0$

**Критерий для нашего исследования**: $p < 0.05$ для признания различия статистически значимым.

#### Обоснование выбора параметрического критерия Стьюдента

**Альтернативные методы проверки гипотезы о равенстве средних**:

1. **Параметрический t-критерий Стьюдента**:
   - Предположение: Нормальность распределений в обеих выборках.
   - Мощность: Высокая при нормальности.
   - Робастность: Умеренная к нарушениям нормальности при больших выборках ($N \geq 30$).

2. **Непараметрический критерий Манна-Уитни** (U-критерий):
   - Предположение: Только непрерывность распределений.
   - Мощность: Ниже, чем у t-критерия при нормальности (эффективность $\approx 95.5\%$).
   - Робастность: Высокая к нарушениям нормальности, применим для произвольных распределений.

3. **Критерий Уилкоксона** (для парных выборок):
   - Непараметрический аналог парного t-критерия.
   - Применим, когда измерения парные (до/после, два метода на одних данных).

4. **Перестановочный критерий** (permutation test):
   - Непараметрический метод, основанный на перестановках.
   - Не требует предположений о распределении.
   - Вычислительно затратен, требует симуляций.

5. **Бутстрап-критерий**:
   - Основан на повторной выборке (bootstrap resampling).
   - Применим для малых выборок и сложных статистик.
   - Вычислительно затратен.

**Математическое обоснование выбора критерия Стьюдента**:

1. **Теорема о максимальной мощности (лемма Неймана-Пирсона)**. Для проверки гипотезы $H_0: \mu_1 = \mu_2$ против альтернативы $H_1: \mu_1 \neq \mu_2$ при известных нормальных распределениях $\mathcal{N}(\mu_1, \sigma^2)$ и $\mathcal{N}(\mu_2, \sigma^2)$ наиболее мощным критерием уровня $\alpha$ является t-критерий Стьюдента. Математически, мощность функции:
   $$
   \beta(\mu_1 - \mu_2) = P_{\mu_1, \mu_2}(|t| > t_{1-\alpha/2, N_1+N_2-2})
   $$
   максимальна среди всех критериев с уровнем значимости $\alpha$. Это означает, что для обнаружения различия заданной величины $\delta = \mu_1 - \mu_2$ требуется минимальный объем выборки по сравнению с любым другим тестом.

2. **Количественное сравнение мощности с непараметрическими тестами**. Асимптотическая относительная эффективность (ARE) критерия Манна-Уитни относительно t-теста Стьюдента при нормальности:
   $$
   \text{ARE}(MW, t) = \frac{3}{\pi} \approx 0.955.
   $$
   Это означает: для достижения той же мощности, что t-тест с выборкой $N$, критерий Манна-Уитни требует выборку $N / 0.955 \approx 1.047 N$. Для $N = 1000$ это дополнительные 47 измерений. При требовании $\delta < 1\%$ такая потеря эффективности недопустима, так как увеличивает относительную погрешность на $\approx 2.3\%$.

3. **Обоснованность предположения нормальности из физики процесса**. Время выполнения $T$ криптографической операции складывается из:
   $$
   T = \underbrace{\sum_{i=1}^{K_{\text{инстр}}} t_{\text{CPU}}^{(i)}}_{\text{детерминированное}} + \underbrace{\sum_{j=1}^{K_{\text{cache}}} t_{\text{cache}}^{(j)}}_{\text{случайное}} + \underbrace{\sum_{k=1}^{K_{\text{mem}}} t_{\text{mem}}^{(k)}}_{\text{случайное}},
   $$
   где $K_{\text{инстр}} \sim 10^6$ (число инструкций), $K_{\text{cache}} \sim 10^3$ (cache miss), $K_{\text{mem}} \sim 10^1$ (memory access). По центральной предельной теореме при $K \gg 1$:
   $$
   T - \mathbb{E}[T] \xrightarrow{d} \mathcal{N}\left(0, \sum_i \text{Var}[t_i]\right).
   $$
   Эмпирическая проверка: при контролируемых условиях $CV = s/\bar{T} < 10\%$. Для нормального распределения вероятность $CV < 10\%$ высока, тогда как для других распределений (экспоненциальное, равномерное) типичные значения $CV$ выше.

4. **Робастность t-теста при больших выборках (теорема Бокса)**. Пусть $X_1, \ldots, X_N$ — независимая выборка из распределения с конечными моментами $\mathbb{E}[X] = \mu$, $\text{Var}[X] = \sigma^2$, $\mathbb{E}[|X - \mu|^3] < \infty$. Тогда при $N \to \infty$:
   $$
   t = \frac{\bar{X} - \mu}{s/\sqrt{N}} \xrightarrow{d} \mathcal{N}(0, 1),
   $$
   независимо от распределения $X$ (асимптотическая нормальность). Для $N = 1000$ сходимость достигнута с высокой точностью: отклонение квантилей распределения $t$ от нормального < 1% даже при умеренной асимметрии ($|\gamma_1| < 1$) исходного распределения.

5. **Минимизация вероятности ошибки II рода при заданном объеме выборки**. Цель исследования — обнаружить различие в производительности $\delta \geq 10\%$ (например, ускорение FAST_V4 vs DEFAULT). Для t-теста при $\alpha = 0.05$, $N = 1000$ мощность обнаружения $\delta = 10\%$ при $CV = 5\%$:
   $$
   \beta \approx \Phi\left(\frac{\delta \sqrt{N}}{CV} - 1.96\right) = \Phi\left(\frac{0.10 \times \sqrt{1000}}{0.05} - 1.96\right) = \Phi(61.2) \approx 1.
   $$
   Для критерия Манна-Уитни мощность снижается до $\beta \approx 0.998$ при тех же условиях, что увеличивает вероятность пропуска значимого различия.

6. **Соответствие цели: гарантированная точность оценки различий**. Цель — не просто обнаружить различие, но оценить его величину с точностью $\delta < 1\%$. Доверительный интервал для разности средних:
   $$
   (\mu_1 - \mu_2) \in \left[(\bar{T}_1 - \bar{T}_2) \pm t_{1-\alpha/2, \nu} \cdot s_p \sqrt{\frac{1}{N_1} + \frac{1}{N_2}}\right].
   $$
   Ширина интервала минимальна для t-теста среди всех несмещенных оценок, что обеспечивает требуемую точность при минимальном $N$.

**Проверка предположений**:

Для корректного применения критерия Стьюдента рекомендуется предварительная проверка:

1. **Проверка нормальности** (критерий Шапиро-Уилка, Колмогорова-Смирнова):
   - $H_0$: выборка из нормального распределения.
   - Если $p > 0.05$, нормальность не отвергается.

2. **Проверка равенства дисперсий** (критерий Левене, F-критерий):
   - $H_0$: дисперсии равны.
   - Если $p > 0.05$, используется стандартный t-критерий.
   - Если $p < 0.05$, используется критерий Уэлча (модификация с коррекцией степеней свободы).

**Условия применимости непараметрических методов**:
- Явные нарушения нормальности, подтвержденные критерием Шапиро-Уилка ($p < 0.05$) при малых выборках ($N < 100$).
- Малые выборки ($N < 30$) с явной асимметрией ($|\gamma_1| > 2$) или тяжелыми хвостами.
- Наличие множественных выбросов (> 5% измерений), которые нельзя удалить без потери информации.
- Порядковые (ранговые) данные без метрической структуры.

**Вывод**: Критерий Стьюдента выбран на основании теоремы Неймана-Пирсона о максимальной мощности при нормальности, количественного преимущества в эффективности (ARE = 0.955 для непараметрических тестов означает потерю 4.5% эффективности), обоснованности предположения нормальности из физики процесса (ЦПТ для суммы $\sim 10^6$ элементарных операций), робастности при $N = 1000$ (теорема Бокса), минимизации вероятности ошибки II рода и соответствия цели исследования — оценки различий с точностью $\delta < 1\%$ при минимальном объеме выборки. Предусматривается предварительная проверка предположений (нормальность, равенство дисперсий) и возможность перехода к критерию Манна-Уитни при подтвержденных нарушениях.

### 4.6. Распространение погрешностей

**Теорема 4.6.1** (Закон распространения погрешностей). Пусть $y = f(x_1, x_2, \ldots, x_n)$ — функция измеренных величин $x_i$ с погрешностями $\Delta x_i$. Тогда погрешность $y$ определяется как
$$
(\Delta y)^2 = \sum_{i=1}^{n} \left(\frac{\partial f}{\partial x_i}\right)^2 (\Delta x_i)^2 + 2 \sum_{i < j} \frac{\partial f}{\partial x_i} \frac{\partial f}{\partial x_j} \text{cov}(x_i, x_j).
$$

**Для независимых величин** ($\text{cov}(x_i, x_j) = 0$):
$$
(\Delta y)^2 = \sum_{i=1}^{n} \left(\frac{\partial f}{\partial x_i}\right)^2 (\Delta x_i)^2.
$$

**Применение к коэффициенту ускорения**:
$$
S = \frac{T_{\text{базовая}}}{T_{\text{опт}}}.
$$

**Частные производные**:
$$
\frac{\partial S}{\partial T_{\text{базовая}}} = \frac{1}{T_{\text{опт}}}, \quad \frac{\partial S}{\partial T_{\text{опт}}} = -\frac{T_{\text{базовая}}}{T_{\text{опт}}^2}.
$$

**Абсолютная погрешность** $S$:
$$
\Delta S = \sqrt{\left(\frac{1}{T_{\text{опт}}}\right)^2 (\Delta T_{\text{базовая}})^2 + \left(\frac{T_{\text{базовая}}}{T_{\text{опт}}^2}\right)^2 (\Delta T_{\text{опт}})^2}.
$$

**Относительная погрешность** $S$:
$$
\frac{\Delta S}{S} = \sqrt{\left(\frac{\Delta T_{\text{базовая}}}{T_{\text{базовая}}}\right)^2 + \left(\frac{\Delta T_{\text{опт}}}{T_{\text{опт}}}\right)^2}.
$$

**Пример**:
$$
T_{\text{базовая}} = 67.74 \pm 0.19~\text{мкс}, \quad T_{\text{опт}} = 50.50 \pm 0.14~\text{мкс}.
$$
$$
S = \frac{67.74}{50.50} = 1.341.
$$
$$
\frac{\Delta S}{S} = \sqrt{\left(\frac{0.19}{67.74}\right)^2 + \left(\frac{0.14}{50.50}\right)^2} = \sqrt{0.0028^2 + 0.0028^2} = 0.0039.
$$
$$
\Delta S = 1.341 \times 0.0039 = 0.005.
$$
$$
S = 1.34 \pm 0.01~(\text{95\% ДИ}).
$$

---

## 5. ПЛАНИРОВАНИЕ ЭКСПЕРИМЕНТА

### 5.1. Факторы и отклики

**Факторы** (независимые переменные):
1. **Конфигурация** (качественный фактор):
   - DEFAULT
   - FAST_V4
   - GOST
   - GOST_FAST

2. **Режим обработки** (качественный фактор):
   - Sequential (последовательная обработка)
   - Batched (батчинговая обработка)

3. **Тип операции** (качественный фактор):
   - KeyGen (генерация ключевой пары)
   - Encaps (инкапсуляция)
   - Decaps (декапсуляция)

**Отклики** (зависимые переменные):
1. Время выполнения $T$ (мкс)
2. Пропускная способность $\Theta = 1/T$ (оп/с)
3. Коэффициент ускорения $S$ (безразмерная величина)

### 5.2. План эксперимента

**Тип плана**: Полный факторный эксперимент $4 \times 2 \times 3 = 24$ комбинации факторов.

**Структура плана**:

| № | Конфигурация | Режим | Операция | Объем выборки $N$ |
|---|-------------|-------|----------|------------------|
| 1 | DEFAULT | Sequential | KeyGen | 1000 |
| 2 | DEFAULT | Sequential | Encaps | 1000 |
| 3 | DEFAULT | Sequential | Decaps | 1000 |
| ... | ... | ... | ... | ... |
| 24 | GOST_FAST | Batched | Decaps | 1000 |

**Рандомизация**: Порядок выполнения экспериментов рандомизируется для устранения влияния систематических факторов (эффект тренда, нагрев процессора и т.д.).

### 5.3. Обоснование объема выборки

**Исходные данные** (пилотный эксперимент):
- Ожидаемый $CV \approx 5\%$
- Требуемая относительная погрешность: $\delta < 1\%$
- Уровень доверия: $1 - \alpha = 0.95$

**Формула** для расчета $N$:
$$
N \geq \left(\frac{z_{1-\alpha/2} \times CV}{\delta}\right)^2.
$$

**Подстановка**:
$$
N \geq \left(\frac{1.96 \times 5}{1}\right)^2 = 96.
$$

**С запасом**: $N = 1000$ обеспечивает $\delta \approx 0.3\%$ при $CV = 5\%$.

---

## 6. ПРОТОКОЛ ПРОВЕДЕНИЯ ЭКСПЕРИМЕНТА

### 6.1. Подготовка экспериментальной установки

#### 6.1.1. Аппаратная платформа

**Процессор**: ARM64 архитектура (ARMv8-A или новее) с поддержкой NEON SIMD.

**Конкретные платформы**:
- ARM Neoverse-N1 (серверный процессор)
- Apple M-серия (клиентские устройства высокой производительности)

**Требования к процессору**:
- Фиксированная частота (отключение динамического масштабирования)
- Изоляция ядра от операционной системы
- Отключение технологий turbo-boost / dynamic frequency scaling

#### 6.1.2. Программное обеспечение

**Операционная система**: Linux (ядро 5.4 или новее).

**Компилятор**: GCC 9+ или Clang 12+.

**Флаги компиляции**:
```
-O3 -march=native -DNDEBUG
```

**Таймер**: `clock_gettime(CLOCK_MONOTONIC, ...)` с разрешением $\geq 1$ нс.

**Обоснование выбора `CLOCK_MONOTONIC`**: Монотонные часы не подвержены изменениям системного времени (NTP, изменения пользователем) и обеспечивают строго возрастающую последовательность.

#### 6.1.3. Контроль условий эксперимента

**Изоляция процесса**:
```bash
taskset -c 0 nice -n -20 ./benchmark
```
- `taskset -c 0` — привязка к ядру #0
- `nice -n -20` — максимальный приоритет

**Фиксация частоты**:
```bash
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
```

**Отключение турбо-буста** (Intel/AMD):
```bash
echo 0 | sudo tee /sys/devices/system/cpu/cpufreq/boost
```

**Изоляция ядра от планировщика** (добавить в параметры ядра):
```
isolcpus=0
```

**Очистка кэша** перед каждой серией:
```bash
sync && echo 3 | sudo tee /proc/sys/vm/drop_caches
```

### 6.2. Алгоритм проведения измерений

**Алгоритм 6.2.1** (Протокол единичного эксперимента)

**Вход**: Функция $f$ (криптографическая операция), параметры $N$ (объем выборки), $M$ (размер warmup).

**Выход**: Массив измерений $\{T_1, T_2, \ldots, T_N\}$.

**Шаги**:

1. **Разминка** (warmup):
   ```
   ДЛЯ i ОТ 1 ДО M:
       Выполнить f()
   КОНЕЦ ДЛЯ
   ```
   **Цель**: Прогрев кэша инструкций и данных, стабилизация состояния процессора.
   **Рекомендуемое значение**: $M \geq 100$.

2. **Основные измерения**:
   ```
   ДЛЯ i ОТ 1 ДО N:
       t_start ← clock_gettime(CLOCK_MONOTONIC)
       Выполнить f()
       t_end ← clock_gettime(CLOCK_MONOTONIC)
       T[i] ← (t_end - t_start) в микросекундах
   КОНЕЦ ДЛЯ
   ```

3. **Возврат**: Массив $T[1..N]$.

### 6.3. Обработка результатов

**Алгоритм 6.3.1** (Статистическая обработка)

**Вход**: Массив измерений $\{T_1, \ldots, T_N\}$, уровень значимости $\alpha$.

**Выход**: $\bar{T}$, $s$, ДИ, $CV$.

**Шаги**:

1. **Вычисление выборочных характеристик**:
   $$
   \bar{T} = \frac{1}{N} \sum_{i=1}^{N} T_i, \quad s = \sqrt{\frac{1}{N-1} \sum_{i=1}^{N} (T_i - \bar{T})^2}.
   $$

2. **Обнаружение и удаление выбросов** (критерий 3σ):
   ```
   outliers ← {}
   ДЛЯ i ОТ 1 ДО N:
       ЕСЛИ |T[i] - T̄| > 3s:
           outliers ← outliers ∪ {i}
       КОНЕЦ ЕСЛИ
   КОНЕЦ ДЛЯ

   ЕСЛИ |outliers| / N > 0.05:
       ВЫВОД "Предупреждение: Удалено >5% измерений. Рекомендуется повторить эксперимент."
   КОНЕЦ ЕСЛИ

   T_clean ← T без элементов из outliers
   Пересчитать T̄, s по T_clean
   ```

3. **Вычисление доверительного интервала**:
   $$
   t_{\text{квантиль}} \leftarrow t_{1-\alpha/2, N-1}.
   $$
   $$
   \text{ДИ} = \left[\bar{T} - t_{\text{квантиль}} \frac{s}{\sqrt{N}}, \bar{T} + t_{\text{квантиль}} \frac{s}{\sqrt{N}}\right].
   $$

4. **Вычисление коэффициента вариации**:
   $$
   CV = \frac{s}{\bar{T}} \times 100\%.
   $$

5. **Возврат**: $(\bar{T}, s, \text{ДИ}, CV)$.

---

## 7. КРИТЕРИИ ВАЛИДНОСТИ ЭКСПЕРИМЕНТА

### 7.1. Критерий стабильности измерений

**Критерий 7.1.1**:
$$
CV < 10\% \quad \text{для всех конфигураций}.
$$

**Обоснование**: По Кобзарю А.И., $CV < 10\%$ соответствует низкой вариабельности, что свидетельствует о хорошем контроле условий эксперимента.

### 7.2. Критерий точности оценки среднего

**Критерий 7.2.1**:
$$
\delta_{\bar{T}} = \frac{t_{1-\alpha/2, N-1} \times s}{\sqrt{N} \times \bar{T}} \times 100\% < 1\%.
$$

**Обоснование**: Относительная погрешность < 1% обеспечивает высокую точность оценки среднего времени выполнения.

### 7.3. Критерий статистической значимости различий

**Критерий 7.3.1**: Для сравнения двух конфигураций (базовая vs оптимизированная):
$$
p\text{-value} < 0.05.
$$

**Обоснование**: Стандартный уровень значимости $\alpha = 0.05$ соответствует вероятности ошибки первого рода (ложное отклонение $H_0$) не более 5%.

### 7.4. Критерий воспроизводимости

**Критерий 7.4.1**: При повторении эксперимента результаты должны попадать в доверительный интервал первоначального эксперимента:
$$
|\bar{T}_{\text{повтор}} - \bar{T}_{\text{оригинал}}| \leq 1.96 \times \sqrt{\frac{s_1^2}{N_1} + \frac{s_2^2}{N_2}}.
$$

**Обоснование**: Согласуется с 95% доверительным интервалом для разности средних.

### 7.5. Критерий согласованности с теоретической моделью

**Критерий 7.5.1**: Экспериментальное ускорение не должно превышать теоретически максимальное более чем на 20%:
$$
S_{\text{эксп}} \leq 1.2 \times S_{\text{макс}},
$$
где $S_{\text{макс}}$ определяется законом Амдаля.

**Обоснование**: Превышение теоретического предела может указывать на систематические ошибки в измерениях или некорректность модели.

---

## 8. ПРЕДСТАВЛЕНИЕ И ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ

### 8.1. Табличное представление

**Таблица 8.1.1** (Шаблон представления результатов)

| Конфигурация | Операция | $\bar{T}$ (мкс) | $s$ (мкс) | 95% ДИ (мкс) | $CV$ (%) | $N$ |
|-------------|----------|---------------|----------|-------------|----------|-----|
| FAST_V4 | 2× Sequential | 67.74 | 3.04 | [67.55, 67.93] | 4.49 | 1000 |
| FAST_V4 | 2× Batched | 50.50 | 2.27 | [50.36, 50.64] | 4.49 | 1000 |

**Таблица 8.1.2** (Сравнительный анализ)

| Сравнение | $\bar{T}_{\text{базовая}}$ | $\bar{T}_{\text{опт}}$ | $S$ | $\Delta S$ | $p$-value | Вывод |
|-----------|--------------------------|----------------------|-----|-----------|-----------|-------|
| FAST_V4 Seq vs Batch | 67.74 | 50.50 | 1.34 | 0.01 | <0.001 | Значимо |

### 8.2. Графическое представление

#### 8.2.1. Столбчатая диаграмма с планками погрешностей

**Оси**:
- **X**: Конфигурации (категориальная шкала)
- **Y**: Время выполнения (мкс, линейная шкала)

**Элементы**:
- Столбцы: Высота = $\bar{T}$
- Планки погрешностей: От $\bar{T} - \Delta T$ до $\bar{T} + \Delta T$, где $\Delta T$ — полуширина 95% ДИ

**Требования к оформлению** (ГОСТ 2.105-95):
- Заголовок: "Рисунок X — Сравнение времени выполнения операции KeyGen"
- Подпись осей с указанием размерности
- Легенда для различных конфигураций

#### 8.2.2. График зависимости времени от размера батча

**Оси**:
- **X**: Размер батча $n$ (1, 2, 4, 8, ...)
- **Y**: Время на одну операцию $T_{\text{батч}}(n) / n$ (мкс)

**Кривые**:
1. **Экспериментальные точки** с планками погрешностей
2. **Аппроксимация МНК**: $y = a + b/n$
3. **Теоретическая модель** (если доступна)

**Метод наименьших квадратов** (МНК):

**Модель**:
$$
f(n; a, b) = a + \frac{b}{n}.
$$

**Функционал качества**:
$$
Q(a, b) = \sum_{i=1}^{m} \left(y_i - \left(a + \frac{b}{n_i}\right)\right)^2 \to \min,
$$
где $y_i = T_{\text{батч}}(n_i) / n_i$ — экспериментальные значения.

**Система нормальных уравнений**:
$$
\begin{cases}
m a + \left(\sum_{i=1}^{m} \frac{1}{n_i}\right) b = \sum_{i=1}^{m} y_i, \\
\left(\sum_{i=1}^{m} \frac{1}{n_i}\right) a + \left(\sum_{i=1}^{m} \frac{1}{n_i^2}\right) b = \sum_{i=1}^{m} \frac{y_i}{n_i}.
\end{cases}
$$

**Решение** (матричная форма):
$$
\begin{pmatrix} a \\ b \end{pmatrix} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y},
$$
где
$$
\mathbf{X} = \begin{pmatrix} 1 & 1/n_1 \\ 1 & 1/n_2 \\ \vdots & \vdots \\ 1 & 1/n_m \end{pmatrix}, \quad \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_m \end{pmatrix}.
$$

**Оценка качества аппроксимации** (коэффициент детерминации):
$$
R^2 = 1 - \frac{\sum_{i=1}^{m} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{m} (y_i - \bar{y})^2},
$$
где $\hat{y}_i = a + b/n_i$ — предсказанные значения, $\bar{y}$ — среднее экспериментальных значений.

**Интерпретация**:
- $R^2 > 0.95$ — отличное соответствие модели
- $0.90 < R^2 \leq 0.95$ — хорошее соответствие
- $R^2 \leq 0.90$ — модель требует пересмотра

#### 8.2.3. График ускорения (speedup plot)

**Оси**:
- **X**: Размер батча $n$
- **Y**: Коэффициент ускорения $S(n) = n T_{\text{одна}} / T_{\text{батч}}(n)$

**Кривые**:
1. **Идеальное масштабирование**: $S_{\text{ideal}}(n) = n$ (прямая линия)
2. **Закон Амдаля**: $S_{\text{Amdahl}}(n) = 1 / ((1-p) + p/n)$
3. **Экспериментальные точки** с погрешностями

**Интерпретация**:
- Близость к идеальной прямой — высокая эффективность параллелизации
- Близость к кривой Амдаля — соответствие теоретической модели
- Отклонение вверх — дополнительные выгоды (кэш, SIMD)
- Отклонение вниз — потери на синхронизацию, накладные расходы

#### 8.2.4. Группированная столбчатая диаграмма (Grouped bar chart)

**Назначение**: Сравнение производительности различных конфигураций для каждой операции.

**Структура**:
- **Ось X**: Тип операции (KeyGen, Encaps, Decaps)
- **Ось Y**: Время выполнения (мкс, логарифмическая или линейная шкала)
- **Группы**: Для каждой операции — группа из 4 столбцов (DEFAULT, FAST_V4, GOST, GOST_FAST)
- **Цветовое кодирование**: Каждая конфигурация имеет свой цвет
- **Планки погрешностей**: 95% доверительный интервал для каждого столбца

**Пример организации**:
```
  KeyGen              Encaps              Decaps
[D][F][G][GF]    [D][F][G][GF]    [D][F][G][GF]
```
где D = DEFAULT, F = FAST_V4, G = GOST, GF = GOST_FAST.

**Требования к оформлению**:
- Легенда с обозначениями конфигураций
- Заголовок: "Рисунок N — Сравнение времени выполнения операций KEM для различных конфигураций"
- Подпись оси Y: "Время выполнения, мкс"
- Сетка для удобства считывания значений

**Интерпретация**:
- Сравнение высоты столбцов в пределах одной группы показывает эффект оптимизаций
- Сравнение между группами показывает, какая операция наиболее затратна
- Отсутствие пересечения планок погрешностей свидетельствует о статистической значимости различий

#### 8.2.5. Сравнение последовательного и батчингового режимов

**Назначение**: Наглядная демонстрация эффективности батчинга для каждой конфигурации.

**Вариант A: Парные столбцы**

**Структура**:
- **Ось X**: Конфигурация × Операция (12 групп: 4 конфигурации × 3 операции)
- **Ось Y**: Время на одну операцию (мкс)
- **В каждой группе**: 2 столбца
  - Светлый: $T_{\text{seq}} = T_{\text{одна}}$ (Sequential, время одной операции)
  - Темный: $T_{\text{batch}} = T_{\text{batch}}(2) / 2$ (Batched, время на операцию в батче из 2)
- **Планки погрешностей**: 95% ДИ

**Аннотация**: Над каждой парой указать коэффициент ускорения $S = T_{\text{seq}} / T_{\text{batch}}$.

**Пример**:
```
FAST_V4 KeyGen:  [■■■ 33.9] [■ 25.4]  S=1.34×
```

**Вариант B: Отклонение от базовой линии**

**Структура**:
- **Ось X**: Конфигурация
- **Ось Y**: Процентное улучшение, %
- **Формула**: $\text{Улучшение} = (1 - T_{\text{batch}} / T_{\text{seq}}) \times 100\%$
- **Столбцы**: Для каждой конфигурации — 3 столбца (KeyGen, Encaps, Decaps)

**Интерпретация**:
- Положительные значения — выигрыш от батчинга
- Чем выше столбец, тем эффективнее батчинг
- Сравнение между операциями показывает, где батчинг наиболее эффективен

#### 8.2.6. Тепловая карта коэффициентов ускорения (Heatmap)

**Назначение**: Визуализация ускорений для всех комбинаций конфигурация × операция.

**Структура**:
- **Строки**: Конфигурации (DEFAULT, FAST_V4, GOST, GOST_FAST)
- **Столбцы**: Операции (KeyGen, Encaps, Decaps)
- **Ячейки**: Коэффициент ускорения $S = T_{\text{seq}}(2) / T_{\text{batch}}(2)$
- **Цветовая шкала**:
  - Холодные тона (синий): $S < 1.2$ (низкое ускорение)
  - Теплые тона (желтый): $1.2 \leq S < 1.4$ (умеренное ускорение)
  - Горячие тона (красный): $S \geq 1.4$ (высокое ускорение)

**Пример**:
```
              KeyGen  Encaps  Decaps
DEFAULT        1.18    1.15    1.12
FAST_V4        1.34    1.32    1.30
GOST           1.22    1.20    1.18
GOST_FAST      1.36    1.35    1.33
```

**Аннотация в ячейках**: Точное значение $S$ с точностью до 0.01.

**Требования к оформлению**:
- Цветовая шкала справа с границами диапазонов
- Заголовок: "Рисунок N — Тепловая карта коэффициентов ускорения батчинга"
- Подпись: "Цвет ячейки соответствует величине ускорения $S = T_{\text{sequential}}(2) / T_{\text{batch}}(2)$"

**Интерпретация**:
- Позволяет быстро идентифицировать наиболее эффективные комбинации
- Визуализирует паттерны: например, все FAST конфигурации показывают высокое ускорение
- Выявляет аномалии: ячейки с неожиданно низким/высоким значением

#### 8.2.7. Диаграмма размахов (Box plot)

**Назначение**: Визуализация распределения времени выполнения и стабильности измерений.

**Структура**:
- **Ось X**: Конфигурация × Режим (8 групп: 4 конфигурации × 2 режима [Sequential, Batched])
- **Ось Y**: Время выполнения одной операции (мкс)
- **Элементы box plot**:
  - Нижняя граница ящика: Первый квартиль $Q_1$ (25-й перцентиль)
  - Центральная линия: Медиана $Q_2$ (50-й перцентиль)
  - Верхняя граница ящика: Третий квартиль $Q_3$ (75-й перцентиль)
  - Усы: $[Q_1 - 1.5 \times IQR, Q_3 + 1.5 \times IQR]$, где $IQR = Q_3 - Q_1$
  - Выбросы: Точки за пределами усов
- **Дополнительно**: Маркер среднего значения $\bar{T}$ (например, крестик)

**Пример для FAST_V4 KeyGen**:
```
Sequential: [──┤■■■├──]  ×   (медиана ≈ среднему при симметричном распределении)
Batched:    [─┤■■├─]  ×      (меньший разброс)
```

**Интерпретация**:

1. **Сравнение центральных тенденций**: Положение медианы (центральная линия) показывает типичное время выполнения.

2. **Оценка вариабельности**: Высота ящика ($IQR$) характеризует разброс:
   - Узкий ящик — низкая вариабельность, стабильные измерения
   - Широкий ящик — высокая вариабельность, нестабильные условия

3. **Асимметрия распределения**:
   - Медиана посередине ящика — симметричное распределение
   - Медиана смещена — асимметричное распределение

4. **Выбросы**: Наличие точек за усами указывает на аномальные измерения, требующие анализа.

5. **Сравнение режимов**:
   - Если ящики не перекрываются — сильное различие
   - Частичное перекрытие — умеренное различие
   - Полное перекрытие — различие незначимо

**Требования к оформлению**:
- Заголовок: "Рисунок N — Распределение времени выполнения операции KeyGen для различных конфигураций и режимов"
- Легенда с обозначением элементов box plot
- Подпись оси Y: "Время выполнения, мкс"
- Горизонтальная сетка

**Дополнительный вариант: Violin plot**

Вместо box plot можно использовать violin plot, который совмещает box plot с оценкой плотности распределения (kernel density estimation). Это дает более полное представление о форме распределения, но требует более сложных графических библиотек.

#### 8.2.8. Составная столбчатая диаграмма декомпозиции (Stacked bar chart)

**Назначение**: Визуализация декомпозиции времени выполнения операции на составные части.

**Применимость**: Требует инструментированной версии кода с измерением времени каждого компонента.

**Структура**:
- **Ось X**: Конфигурация × Режим
- **Ось Y**: Время выполнения (мкс)
- **Составные части столбца** (снизу вверх для KeyGen):
  1. $T_{\text{матрица}}$ — генерация матрицы (например, зеленый)
  2. $T_{\text{секрет}}$ — генерация секрета (синий)
  3. $T_{\text{умножение}}$ — умножение матрицы на вектор (оранжевый)
  4. $T_{\text{упаковка}}$ — сжатие и упаковка (желтый)
  5. $T_{\text{хеш}}$ — хеширование открытого ключа (красный)

**Пример**:
```
Sequential:  [■■■■■■ Matrix ■■■■■■][■■ Secret ■■][■■■■ MatVec ■■■■][■ Pack ■][■ Hash ■]
Batched:     [■■■■■■ Matrix ■■■■■■][■■■■ Secret ■■■■][■■■■■■■■ MatVec ■■■■■■■■][■■ Pack ■■][■■ Hash ■■]
```

**Интерпретация**:

1. **Идентификация узких мест**: Самый высокий сегмент указывает на наиболее затратную операцию.

2. **Эффект батчинга**:
   - Сегмент "Matrix" в батчинге не увеличивается (разделяется между операциями)
   - Другие сегменты увеличиваются пропорционально

3. **Доля разделяемого кода**: $p = T_{\text{матрица}} / T_{\text{total}}$ визуально очевидна как доля зеленого сегмента.

4. **Валидация модели Амдаля**: Сравнение с теоретической декомпозицией.

**Требования к оформлению**:
- Легенда с обозначениями компонентов и их цветами
- Заголовок: "Рисунок N — Декомпозиция времени выполнения операции KeyGen"
- Подпись оси Y: "Время выполнения, мкс"
- Аннотации с процентной долей каждого компонента (опционально)

**Примечание**: Данный тип графика требует инструментации кода для измерения времени каждого компонента отдельно. Это может вносить накладные расходы, поэтому измерения следует проводить в отдельной серии экспериментов, а не смешивать с основными измерениями производительности.

### 8.3. Рекомендации по выбору типа графика

**Таблица 8.3.1** — Соответствие типов графиков исследовательским задачам

| Исследовательская задача | Рекомендуемый тип графика | Раздел |
|-------------------------|--------------------------|--------|
| Сравнить производительность конфигураций | Grouped bar chart | 8.2.4 |
| Показать эффективность батчинга | Парные столбцы (Seq vs Batch) | 8.2.5 |
| Быстро идентифицировать лучшие комбинации | Heatmap | 8.2.6 |
| Оценить стабильность измерений | Box plot | 8.2.7 |
| Выявить узкие места в алгоритме | Stacked bar chart | 8.2.8 |
| Проверить соответствие закону Амдаля | Speedup plot | 8.2.3 |
| Исследовать масштабируемость батчинга | График T(n)/n от n | 8.2.2 |

**Минимальный набор графиков для публикации результатов**:

1. **Обязательные**:
   - Grouped bar chart (8.2.4) — для сравнения конфигураций
   - Парные столбцы Sequential vs Batched (8.2.5) — для демонстрации эффекта батчинга
   - Speedup plot (8.2.3) — для валидации против закона Амдаля

2. **Рекомендуемые**:
   - Box plot (8.2.7) — для подтверждения стабильности измерений (валидация $CV < 10\%$)
   - Heatmap (8.2.6) — для компактного представления всех результатов

3. **Дополнительные** (для углубленного анализа):
   - Stacked bar chart (8.2.8) — при наличии декомпозиции времени
   - График T(n)/n (8.2.2) — при исследовании различных размеров батча ($n > 2$)

**Общие требования к графикам** (согласно ГОСТ 2.105-95):

1. **Нумерация**: Рисунок 1, Рисунок 2, ... (сквозная нумерация)
2. **Подпись**: Под графиком, с указанием названия и краткого пояснения
3. **Ссылка в тексте**: "Как показано на рисунке N, ..."
4. **Оси**: Обязательные подписи с указанием размерности
5. **Легенда**: При наличии нескольких кривых/групп
6. **Шрифты**: Читаемый размер (не менее 10pt для печати)
7. **Цвета**: Различимые в черно-белой печати (использовать также различные штриховки/маркеры)

---

## 9. ТЕОРЕТИЧЕСКАЯ МОДЕЛЬ БАТЧИНГА

### 9.1. Декомпозиция времени выполнения

**Модель**: Время выполнения операции KeyGen представляется как сумма компонент:
$$
T_{\text{KeyGen}} = T_{\text{матрица}} + T_{\text{секрет}} + T_{\text{умножение}} + T_{\text{упаковка}} + T_{\text{хеш}},
$$
где:
- $T_{\text{матрица}}$ — генерация матрицы $\mathbf{A} \in \mathbb{Z}_q^{L \times L \times N}$ из seed
- $T_{\text{секрет}}$ — генерация секретного вектора $\mathbf{s} \in \mathbb{Z}_q^{L \times N}$
- $T_{\text{умножение}}$ — вычисление $\mathbf{b} = \mathbf{A} \mathbf{s} \mod q$
- $T_{\text{упаковка}}$ — сжатие и упаковка $\mathbf{b}$
- $T_{\text{хеш}}$ — хеширование открытого ключа

### 9.2. Модель последовательного выполнения

Для $n$ независимых операций KeyGen:
$$
T_{\text{sequential}}(n) = n \times (T_{\text{матрица}} + T_{\text{секрет}} + T_{\text{умножение}} + T_{\text{упаковка}} + T_{\text{хеш}}).
$$

### 9.3. Модель батчинговой обработки

**Ключевое наблюдение**: Для алгоритма SABER с одинаковым seed матрицы, можно разделить генерацию матрицы между операциями.

**Модель для $n$ операций**:
$$
T_{\text{batch}}(n) = T_{\text{матрица}} + n \times (T_{\text{секрет}} + T_{\text{умножение}}^{\text{SIMD}} + T_{\text{упаковка}} + T_{\text{хеш}}),
$$
где $T_{\text{умножение}}^{\text{SIMD}} \leq T_{\text{умножение}}$ за счет SIMD-оптимизаций.

### 9.4. Теоретическое ускорение

**Для $n=2$**:
$$
S_{\text{теория}}(2) = \frac{T_{\text{sequential}}(2)}{T_{\text{batch}}(2)} = \frac{2(T_{\text{матрица}} + T_{\text{секрет}} + T_{\text{умножение}} + T_{\text{упаковка}} + T_{\text{хеш}})}{T_{\text{матрица}} + 2(T_{\text{секрет}} + \alpha T_{\text{умножение}} + T_{\text{упаковка}} + T_{\text{хеш}})},
$$
где $\alpha \in [0.8, 0.9]$ — коэффициент эффективности SIMD.

**Упрощение** (обозначим $T_{\text{матрица}} = \beta T_{\text{total}}$, где $T_{\text{total}}$ — полное время одной операции):
$$
S_{\text{теория}}(2) \approx \frac{2}{1 + \beta + (1 - \beta) \alpha}.
$$

**Численный пример** ($\beta = 0.30$, $\alpha = 0.85$):
$$
S_{\text{теория}}(2) = \frac{2}{1 + 0.30 + 0.70 \times 0.85} = \frac{2}{1.895} = 1.27.
$$

**Сравнение с экспериментом**: $S_{\text{эксп}} = 1.34$ > $S_{\text{теория}} = 1.27$.

**Объяснение превышения**: Дополнительные выгоды от улучшенной локальности кэша при обработке двух векторов с одной матрицей.

---

## 10. ВЫВОДЫ И РЕКОМЕНДАЦИИ

### 10.1. Методологические выводы

1. **Разработанная методология** обеспечивает строгость экспериментального исследования производительности криптографических алгоритмов в соответствии с принципами классической русской научной школы математической статистики (Боровков, Налимов, Ермаков).

2. **Применение методов** планирования эксперимента, статистической обработки данных и теории погрешностей позволяет получать **воспроизводимые** результаты с количественной оценкой достоверности.

3. **Критерии валидности** ($CV < 10\%$, $\delta < 1\%$, $p < 0.05$) обеспечивают высокое качество экспериментальных данных и статистическую значимость выводов.

### 10.2. Практические рекомендации

1. **Объем выборки**: Рекомендуется $N \geq 1000$ измерений для достижения относительной погрешности $\delta < 1\%$ при типичных значениях $CV = 5-10\%$.

2. **Контроль условий**: Критически важна изоляция процесса (фиксация на ядре, максимальный приоритет, фиксированная частота) для обеспечения $CV < 10\%$.

3. **Обработка выбросов**: Применение критерия 3σ с контролем доли удаленных измерений (< 5%) предотвращает искажение результатов от аномальных значений.

4. **Проверка гипотез**: Обязательное применение t-теста Стьюдента для подтверждения статистической значимости различий между конфигурациями.

### 10.3. Применимость к исследованию батчинга SABER

**Для оценки эффективности батчинга** необходимо:

1. **Измерить** время последовательного выполнения 2 операций: $T_{\text{seq}}(2) = 2 \times T_{\text{одна}}$

2. **Измерить** время батчинговой обработки 2 операций: $T_{\text{batch}}(2)$

3. **Вычислить** коэффициент ускорения:
   $$
   S = \frac{T_{\text{seq}}(2)}{T_{\text{batch}}(2)}.
   $$

4. **Проверить** статистическую значимость различия ($p < 0.05$).

5. **Сравнить** с теоретической моделью (закон Амдаля).

**Ожидаемый результат** (на основе предварительных данных):
$$
S_{\text{FAST\_V4}} \approx 1.3-1.4, \quad S_{\text{GOST\_FAST}} \approx 1.3-1.4.
$$

**Интерпретация**: Батчинг обеспечивает ускорение на 30-40%, что соответствует теоретическим ограничениям закона Амдаля при 30% разделяемого кода.

---

## СПИСОК ЛИТЕРАТУРЫ

1. **Боровков А.А.** Математическая статистика. — М.: Наука, 1984. — 472 с.

2. **Налимов В.В., Чернова Н.А.** Статистические методы планирования экстремальных экспериментов. — М.: Наука, 1965. — 340 с.

3. **Ермаков С.М., Жиглявский А.А.** Математическая теория оптимального эксперимента. — Л.: Наука, 1987. — 320 с.

4. **Вентцель Е.С.** Теория вероятностей. — М.: Наука, 1969. — 576 с.

5. **Гмурман В.Е.** Теория вероятностей и математическая статистика. — М.: Высшая школа, 2003. — 479 с.

6. **Кобзарь А.И.** Прикладная математическая статистика. Для инженеров и научных работников. — М.: Физматлит, 2006. — 816 с.

7. **Зайдель А.Н.** Погрешности измерений физических величин. — Л.: Наука, 1985. — 112 с.

8. **Рабинович С.Г.** Погрешности измерений. — Л.: Энергия, 1978. — 262 с.

9. **Моисеев Н.Н., Иванилов Ю.П., Столярова Е.М.** Методы оптимизации. — М.: Наука, 1978. — 352 с.

10. **Amdahl G.M.** Validity of the single processor approach to achieving large scale computing capabilities // Proceedings of the AFIPS Spring Joint Computer Conference. — 1967. — Vol. 30. — P. 483–485.

11. **ГОСТ 2.105-95** Единая система конструкторской документации. Общие требования к текстовым документам. — М.: Стандартинформ, 1995.

---

**КОНЕЦ ДОКУМЕНТА**

---

## ИСТОРИЯ ИЗМЕНЕНИЙ

**Версия 1.2** (13 января 2026 г.):
- Полностью переработан раздел 2.0 "Методологические принципы выбора статистических методов":
  - Заменены ссылки на "традицию" и "простоту" математическими обоснованиями
  - Добавлены принципы: несмещенности, оптимальности (теорема Гаусса-Маркова), максимальной мощности (лемма Неймана-Пирсона), соответствия природе данных, объективности, робастности при больших выборках
- Математически обоснованы все выборы статистических методов:
  - Несмещенная оценка дисперсии (4.1.2): доказательство через потерю степени свободы, корректность распределения Стьюдента, количественная оценка систематической ошибки
  - Классические доверительные интервалы (4.2.2): объективность (независимость от априорных предположений), гарантированное покрытие при повторных экспериментах, воспроизводимость результатов
  - Критерий 3σ (4.4): вероятностное обоснование порога, оптимальность при нормальности (баланс ошибок I и II рода), обоснованность нормальности через ЦПТ, мощность обнаружения аномалий, сравнение с критерием Граббса
  - Критерий Стьюдента (4.5.2): теорема Неймана-Пирсона о максимальной мощности, количественное сравнение эффективности (ARE = 0.955 для Манна-Уитни), обоснование нормальности из физики процесса, робастность (теорема Бокса), минимизация ошибки II рода
- Все обоснования основаны на математических теоремах, свойствах оптимальности, особенностях измерения производительности и требованиях к точности ($\delta < 1\%$)

**Версия 1.1** (13 января 2026 г.):
- Добавлен раздел 2.0 "Методологические принципы выбора статистических методов"
- Добавлены подразделы "Обоснование выбора метода" для всех ключевых статистических методов
- Расширен раздел 8.2 "Графическое представление" дополнительными типами графиков:
  - 8.2.4 Группированная столбчатая диаграмма
  - 8.2.5 Сравнение последовательного и батчингового режимов
  - 8.2.6 Тепловая карта коэффициентов ускорения
  - 8.2.7 Диаграмма размахов (Box plot)
  - 8.2.8 Составная столбчатая диаграмма декомпозиции
- Добавлен раздел 8.3 "Рекомендации по выбору типа графика"

**Версия 1.0** (13 января 2026 г.):
- Первоначальная версия методологии

---

*Методология разработана на основе классических трудов русской научной школы математической статистики (Боровков А.А., Налимов В.В., Ермаков С.М., Вентцель Е.С., Гмурман В.Е., Кобзарь А.И., Зайдель А.Н., Рабинович С.Г.) с применением закона Амдаля для анализа параллельных вычислений.*
