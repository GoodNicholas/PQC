# Памятка: Ключевые формулы для измерения производительности

## Основные определения

### Коэффициент ускорения (Speedup)
```
S = T_baseline / T_optimized
```
- S > 1 → ускорение
- S < 1 → замедление
- S = 1 → нет изменений

### Эффективность батчинга
```
E_batch(n) = (n × T_single) / T_batch(n)
```
Где:
- n — размер батча
- T_single — время одной операции
- T_batch(n) — время батча из n операций

### Пример для n=2:
```
T_single = 33.87 μs (FAST_V4 KeyGen)
T_sequential(2) = 2 × 33.87 = 67.74 μs
T_batch(2) = 50.50 μs (измеренное)

Speedup = 67.74 / 50.50 = 1.34×
Улучшение throughput = (1.34 - 1) × 100% = 34%
```

## Статистические метрики

### Выборочное среднее
```
T̄ = (1/N) × Σ T_i
```

### Стандартное отклонение (несмещенное)
```
s = sqrt((1/(N-1)) × Σ(T_i - T̄)²)
```

### Коэффициент вариации
```
CV = (s / T̄) × 100%
```
**Критерий**: CV < 10% для валидных измерений

### 95% Доверительный интервал
```
[T̄ - 1.96×(s/√N), T̄ + 1.96×(s/√N)]
```
Для N ≥ 1000 (приближение нормальным распределением)

### Относительная погрешность
```
δ = (1.96 × s) / (√N × T̄) × 100%
```
**Критерий**: δ < 1% для точных измерений

## Погрешность ускорения

### Формула распространения погрешностей
```
ΔS = S × sqrt((δT_base/T_base)² + (δT_opt/T_opt)²)
```

Где:
```
δT = (1.96 × s) / √N
```

### Пример:
```
T_base = 67.74 ± 0.19 μs
T_opt = 50.50 ± 0.14 μs
S = 1.34

ΔS = 1.34 × sqrt((0.19/67.74)² + (0.14/50.50)²)
   = 1.34 × sqrt(0.0028² + 0.0028²)
   = 1.34 × 0.0039
   = 0.005

Результат: S = 1.34 ± 0.005 (95% ДИ: [1.33, 1.35])
```

## Проверка гипотез (t-тест)

### H₀: T_base = T_opt (нет различия)
### H₁: T_base ≠ T_opt (есть различие)

```
t = (T̄_base - T̄_opt) / sqrt(s²_base/N_base + s²_opt/N_opt)
```

**Решение**:
- Если |t| > 1.96 → отвергаем H₀ (различие значимо при α=0.05)
- Иначе → не отвергаем H₀

## Закон Амдаля

### Максимальное ускорение при параллелизации
```
S_max = 1 / (1 - p)
```

Где p — доля параллелизуемого кода

### Пример:
```
Если 30% кода (генерация матрицы) можно выполнить 1 раз:
p = 0.3
S_max = 1 / (1 - 0.3) = 1.43×

Вывод: Даже идеальная параллелизация остального кода
       не даст ускорение > 1.43×
```

## Модель МНК для зависимости от размера батча

### Модель
```
T_batch(n) / n = a + b/n
```

Где:
- a — асимптотическое время (n → ∞)
- b — overhead фиксированных операций

### Решение МНК
```
Минимизировать: Σ(y_i - (a + b/n_i))²
```

Нормальные уравнения:
```
[a] = (X^T X)^(-1) X^T y
[b]
```

### Коэффициент детерминации R²
```
R² = 1 - Σ(y_i - ŷ_i)² / Σ(y_i - ȳ)²
```

**Критерий**: R² > 0.95 для хорошего соответствия

## Быстрая проверка качества эксперимента

### Чек-лист:
```
☐ N ≥ 1000 измерений
☐ CV < 10% для всех конфигураций
☐ δ < 1% (относительная погрешность среднего)
☐ Удалено < 5% выбросов (метод 3σ)
☐ p-value < 0.05 (статистическая значимость)
☐ Воспроизводимость в пределах ДИ
```

## Шаблон представления результатов

```
Конфигурация: FAST_V4
Операция: KeyGen (2× Batched)

Результаты (N = 1000):
  Mean: 50.50 μs
  Std:  2.27 μs
  CV:   4.49%
  95% ДИ: [50.36, 50.64] μs
  δ:    0.28%

Сравнение с Sequential:
  T_sequential: 67.74 μs
  T_batched:    50.50 μs
  Speedup:      1.34× ± 0.005
  p-value:      < 0.001 (значимо)
  Улучшение:    +34.1% throughput

Критерии валидности:
  ✓ CV < 10%
  ✓ δ < 1%
  ✓ p < 0.05
```

## Практические советы

### Уменьшение вариабельности:
1. Фиксация процесса на одном ядре: `taskset -c 0`
2. Отключение турбо-буста
3. Максимальный приоритет: `nice -n -20`
4. Разминка (warmup) перед измерениями
5. Очистка кэша между экспериментами

### Типичные источники ошибок:
- **Недостаточный N**: CV > 10% → увеличить N
- **Загрязнение кэша**: warmup < 100 итераций
- **Фоновые процессы**: изолировать ядро
- **Динамическая частота**: зафиксировать frequency governor
- **Выбросы**: проверить удаление > 5% данных

### Минимальный протокол для быстрой оценки:
```bash
# 1. Разминка
for i in {1..100}; do ./benchmark > /dev/null; done

# 2. Измерения
for i in {1..1000}; do
  /usr/bin/time -f "%e" ./benchmark 2>&1 | grep -o "[0-9.]*"
done > times.txt

# 3. Анализ
python3 << EOF
import statistics
data = [float(x) for x in open('times.txt').readlines()]
mean = statistics.mean(data)
std = statistics.stdev(data)
cv = 100 * std / mean
print(f"Mean: {mean:.4f} s")
print(f"Std:  {std:.4f} s")
print(f"CV:   {cv:.2f}%")
EOF
```
